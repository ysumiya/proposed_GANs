{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: UTF-8\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import glob\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "from proposal_GANs import MY_GAN\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "class pycolor:\n",
    "    BLACK = '\\033[30m'\n",
    "    RED = '\\033[31m'\n",
    "    GREEN = '\\033[32m'\n",
    "    YELLOW = '\\033[33m'\n",
    "    BLUE = '\\033[34m'\n",
    "    PURPLE = '\\033[35m'\n",
    "    CYAN = '\\033[36m'\n",
    "    WHITE = '\\033[37m'\n",
    "    END = '\\033[0m'\n",
    "    BOLD = '\\038[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    INVISIBLE = '\\033[08m'\n",
    "    REVERCE = '\\033[07m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('logdir', 'param/artifical_fit/',\n",
    "                           \"\"\"Directory where to write event logs and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_string('results_dir', 'data/gan_output/cleared_',\n",
    "                           \"\"\"Directory where to write generated signals.\"\"\")\n",
    "tf.app.flags.DEFINE_string('data_dir', '../data',\n",
    "                           \"\"\"Path to the raw data directory.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_examples_per_epoch_for_train', 5000,\n",
    "                            \"\"\"number of examples for train\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 10,\n",
    "                            \"\"\"Number of steps to run.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64,\n",
    "                            \"\"\"Size of batch in each steps\"\"\")\n",
    "\n",
    "BATCH_LENGTH = 5000\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "TrainData_list = []\n",
    "InputData_list = []\n",
    "Data_list = []\n",
    "\n",
    "#load the eeg data\n",
    "print('loading eeg data ...')\n",
    "\n",
    "train_eeg = pd.read_csv('./data/clear/eeg_B6J10.csv', header=None, index_col=None)\n",
    "train_eeg = train_eeg.as_matrix().reshape(-1, BATCH_LENGTH)\n",
    "train_eeg = train_eeg[0:2000]\n",
    "\n",
    "noisy_eeg = pd.read_csv('./data/noisy/low_noisy_eeg_B6J5.csv', header=None, index_col=None).as_matrix()\n",
    "noisy_eeg = noisy_eeg.reshape(-1,BATCH_LENGTH)\n",
    "noisy_eeg = noisy_eeg[0:2000]\n",
    "\n",
    "clear_F = np.fft.fft(train_eeg)\n",
    "clear_F_amp = abs(clear_F)\n",
    "clear_F_angle= np.angle(clear_F)\n",
    "noisy_F = np.fft.fft(noisy_eeg)\n",
    "noisy_F_amp = abs(noisy_F)\n",
    "noisy_F_angle= np.angle(noisy_F)\n",
    "\n",
    "ylim = [0,450]\n",
    "\n",
    "pre_fig = plt.figure(figsize=(20,10))\n",
    "pre_ax1 = pre_fig.add_subplot(211)\n",
    "pre_ax1.plot(np.mean(clear_F_amp/2500, axis=0)[0:30], label='mean')\n",
    "pre_ax1.plot(np.median(clear_F_amp/2500, axis=0)[0:30], label='median')\n",
    "pre_ax1.plot(stats.scoreatpercentile(clear_F_amp/2500, 25, axis=0)[0:30], label='25')\n",
    "pre_ax1.plot(stats.scoreatpercentile(clear_F_amp/2500, 75, axis=0)[0:30], label='75')\n",
    "plt.ylim(ylim)\n",
    "plt.title('clear')\n",
    "plt.legend()\n",
    "\n",
    "pre_ax2 = pre_fig.add_subplot(212)\n",
    "pre_ax2.plot(np.mean(noisy_F_amp/2500, axis=0)[0:30], label='mean')\n",
    "pre_ax2.plot(np.median(noisy_F_amp/2500, axis=0)[0:30], label='median')\n",
    "pre_ax2.plot(stats.scoreatpercentile(noisy_F_amp/2500, 25, axis=0)[0:30], label='25')\n",
    "pre_ax2.plot(stats.scoreatpercentile(noisy_F_amp/2500, 75, axis=0)[0:30], label='75')\n",
    "plt.ylim(ylim)\n",
    "plt.title('noisy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "mygan = MY_GAN(s_size=4, batch_size=FLAGS.batch_size)\n",
    "\n",
    "noisydata_train_ph = tf.placeholder(tf.float32, shape = [FLAGS.batch_size, 1, BATCH_LENGTH, 1], name='noisydata_train')\n",
    "traindata_train_ph = tf.placeholder(tf.float32, shape = [FLAGS.batch_size, 1, BATCH_LENGTH, 1], name='traindata_train')\n",
    "noisydata_ph = tf.placeholder(tf.float32, shape = [FLAGS.batch_size, 1, BATCH_LENGTH, 1], name='noisydata')\n",
    "\n",
    "losses = mygan.loss(noisydata_train_ph, traindata_train_ph)\n",
    "g_loss_pretraining_op = mygan.loss_G_pretraining(noisydata_train_ph, traindata_train_ph)\n",
    "d_loss_pretraining_op = mygan.loss_D_pretraining(noisydata_train_ph, traindata_train_ph)\n",
    "g_losses = mygan.loss_G_only(noisydata_train_ph, traindata_train_ph)\n",
    "d_losses = mygan.loss_D_only(noisydata_train_ph, traindata_train_ph)\n",
    "train_op = mygan.train(losses, g_learning_rate=0.01, d_learning_rate=0.0001)\n",
    "G_pretraining_op = mygan.G_pretraining(g_loss_pretraining_op, g_learning_rate=0.0001)\n",
    "D_pretraining_op = mygan.D_pretraining(d_loss_pretraining_op, d_learning_rate=0.0001)\n",
    "g_train_only_op = mygan.G_only_training(g_losses, g_learning_rate=0.0001)\n",
    "d_train_only_op = mygan.D_only_training(d_losses, d_learning_rate=0.0001)\n",
    "\n",
    "signals = mygan.sample_signals(inputs = noisydata_ph)\n",
    "\n",
    "clear_ph = tf.placeholder(tf.float32, name='clear')\n",
    "sin_ph = tf.placeholder(tf.float32, name='sin')\n",
    "\n",
    "#feature matching\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "g_saver = tf.train.Saver(dcgan.g.variables, max_to_keep=15)\n",
    "d_saver = tf.train.Saver(dcgan.d.variables, max_to_keep=15)\n",
    "g_checkpoint_path = os.path.join(FLAGS.logdir, 'g/g_fit_4000.ckpt')\n",
    "d_checkpoint_path = os.path.join(FLAGS.logdir, 'd/d_fit_4000.ckpt')\n",
    "\n",
    "g_loss_list = []\n",
    "g_loss_fit_list = []\n",
    "g_loss_rec_list = []\n",
    "g_loss_noise_list = []\n",
    "d_loss_list = []\n",
    "g_predict_list = []\n",
    "t_predict_list = []\n",
    "\n",
    "gpuConfig = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        per_process_gpu_memory_fraction=1.0,\n",
    "        visible_device_list=''),\n",
    "    #device_count={'GPU': 4}\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=gpuConfig) as sess:\n",
    "    #summary_writer = tf.summary.FileWriter(FLAGS.logdir, graph=sess.graph)\n",
    "    # restore or initialize generator\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #g_saver.restore(sess, FLAGS.logdir + 'g/g.ckpt-30')\n",
    "    #g_saver.restore(sess, FLAGS.logdir + 'g_pre/g_pretrained.ckpt-15')\n",
    "    #d_saver.restore(sess, FLAGS.logdir + 'd/d.ckpt-31')\n",
    "\n",
    "    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "\n",
    "    # setup for monitoring\n",
    "\n",
    "    #signals = dcgan.sample_signals(inputs = noisydata_ph)\n",
    "\n",
    "    with tf.name_scope('summary'):\n",
    "        writer = tf.summary.FileWriter('./tensorboard/tensorboard-log', sess.graph)\n",
    "        d_loss_summary = tf.summary.scalar('d_loss', d_losses['d_l'])\n",
    "        g_pre_summary = tf.summary.scalar('g_predict', d_losses['g_pre'][1])\n",
    "        t_pre_summary = tf.summary.scalar('t_predict', d_losses['t_pre'][1])\n",
    "        g_loss_summary = tf.summary.scalar('g_loss', g_losses['g_l'])\n",
    "        g_loss_fit_summary = tf.summary.scalar('g_loss_fit', g_losses['g_lf'])\n",
    "        g_loss_rec_summary = tf.summary.scalar('g_loss_rec', g_losses['g_lr'])\n",
    "        g_loss_noise_summary = tf.summary.scalar('g_loss_noise', g_losses['g_ln'])\n",
    "        g_pre_loss_summary = tf.summary.scalar('g_pre_loss', g_loss_pretraining_op[0])\n",
    "\n",
    "    print 'start training...'\n",
    "    #Wlole system training\n",
    "    for step in range(FLAGS.max_steps):\n",
    "        g_predict_list = []\n",
    "        t_predict_list = []\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        ERROR = tf.constant(0)\n",
    "\n",
    "        #Discriminator training\n",
    "        for batch_step in range(len(train_eeg) / FLAGS.batch_size):\n",
    "            batch_noisy_eeg = noisy_F_amp[batch_step * FLAGS.batch_size : (batch_step + 1) * FLAGS.batch_size, :]\n",
    "            batch_train_eeg = clear_F_amp[batch_step * FLAGS.batch_size : (batch_step + 1) * FLAGS.batch_size, :]\n",
    "\n",
    "            batch_noisy_eeg = np.reshape(batch_noisy_eeg, (-1, 1, BATCH_LENGTH, 1))\n",
    "            batch_train_eeg = np.reshape(batch_train_eeg, (-1, 1, BATCH_LENGTH, 1))\n",
    "            batch_train_dict = {noisydata_train_ph: batch_noisy_eeg, traindata_train_ph: batch_train_eeg}\n",
    "            D_train_list = [d_train_only_op, d_losses['d_l'], d_losses['g_pre'], d_losses['t_pre'], d_loss_summary, g_pre_summary, t_pre_summary, d_losses['err']]\n",
    "\n",
    "            if(batch_noisy_eeg.shape == (FLAGS.batch_size, 1, BATCH_LENGTH, 1) and batch_train_eeg.shape == (FLAGS.batch_size, 1, BATCH_LENGTH, 1)):\n",
    "                _, d_loss, g_predict, t_predict, dl_summary, gp_summary, tp_summary, err = sess.run(\n",
    "                    D_train_list, feed_dict=batch_train_dict)\n",
    "\n",
    "            ERROR = tf.add(ERROR, err)\n",
    "\n",
    "        #print('error rate : {}'.format(sess.run(AMT)))\n",
    "\n",
    "        d_loss_list.append(d_loss)\n",
    "        g_predict_list.append(g_predict[1])\n",
    "        t_predict_list.append(t_predict[1])\n",
    "\n",
    "        #Generator training\n",
    "        for i in range(G_PER_D):\n",
    "\n",
    "            for batch_step in range(len(train_eeg) / FLAGS.batch_size):\n",
    "                batch_noisy_eeg = noisy_F_amp[batch_step * FLAGS.batch_size : (batch_step + 1) * FLAGS.batch_size, :]\n",
    "                batch_train_eeg = clear_F_amp[batch_step * FLAGS.batch_size : (batch_step + 1) * FLAGS.batch_size, :]\n",
    "\n",
    "                batch_noisy_eeg = np.reshape(batch_noisy_eeg, (-1, 1, BATCH_LENGTH, 1))\n",
    "                batch_train_eeg = np.reshape(batch_train_eeg, (-1, 1, BATCH_LENGTH, 1))\n",
    "                batch_train_dict = {noisydata_train_ph: batch_noisy_eeg, traindata_train_ph: batch_train_eeg}\n",
    "                G_train_list = [g_train_only_op, g_losses['g_l'], g_losses['g_lf'], g_losses['g_lr'], g_losses['g_ln'], g_loss_summary, g_loss_fit_summary, g_loss_rec_summary, g_loss_noise_summary]\n",
    "\n",
    "                if(batch_noisy_eeg.shape == (FLAGS.batch_size, 1, BATCH_LENGTH, 1) and batch_train_eeg.shape == (FLAGS.batch_size, 1, BATCH_LENGTH, 1)):\n",
    "                    _, g_loss, g_loss_fit, g_loss_rec, g_loss_noise, gl_summary, glf_summary, glr_summary, gln_summary = sess.run(\n",
    "                        G_train_list, feed_dict=batch_train_dict,\n",
    "                        options=run_options, run_metadata=run_metadata)\n",
    "            print(('g_loss -> ' + pycolor.RED + 'All' + pycolor.END + ': {:e}, ' + pycolor.GREEN + 'Fit' + pycolor.END + ': {:e}, ' + pycolor.YELLOW + 'Rec' + pycolor.END + ': {:e}, ' + pycolor.BLUE + 'Noise' + pycolor.END + ': {:e}').format(g_loss, g_loss_fit, g_loss_rec, g_loss_noise))\n",
    "\n",
    "            g_loss_list.append(g_loss)\n",
    "            g_loss_fit_list.append(g_loss_fit)\n",
    "            g_loss_rec_list.append(g_loss_rec)\n",
    "            g_loss_noise_list.append(g_loss_noise)\n",
    "\n",
    "        t_predict_mean = sum(t_predict_list)/len(t_predict_list)\n",
    "        g_predict_mean = sum(g_predict_list)/len(g_predict_list)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        print('{}: step {:5d}, loss = (Generator: {:e}, Discriminator: {:e}), ({:.3f} sec/batch)'.format(\n",
    "            datetime.now(), step, g_loss, d_loss, duration))\n",
    "        print('')\n",
    "        print('g_loss_fit: {:e}, g_loss_rec: {:e}, g_loss_noise: {:e}'.format(\n",
    "            g_loss_fit, g_loss_rec, g_loss_noise))\n",
    "        print('')\n",
    "        print('Generated is Training: {:e}, Training is Training: {:e}'.format(\n",
    "            g_predict_mean, t_predict_mean))\n",
    "\n",
    "    print('training finished !')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=gpuConfig) as sess:\n",
    "    g_saver.restore(sess, FLAGS.logdir + 'g/g_fit_4000.ckpt-10')\n",
    "    print('prediction noisydata start ...')\n",
    "\n",
    "    test_noisy_eeg = np.empty((0, BATCH_LENGTH))\n",
    "    cleared_F_amp = np.empty((0, BATCH_LENGTH))\n",
    "    noise_F_amp = np.empty((0, BATCH_LENGTH))\n",
    "\n",
    "    test_noisy_eeg = np.append(test_noisy_eeg, pd.read_csv('./data/noisy/low_noisy_eeg_B6J5.csv', header=None, index_col=None).as_matrix())\n",
    "\n",
    "    test_noisy_eeg = test_noisy_eeg.reshape(-1, BATCH_LENGTH)[2000:4000]\n",
    "    test_noisy_F = np.fft.fft(test_noisy_eeg)\n",
    "    test_noisy_F_amp = abs(test_noisy_F)\n",
    "    test_noisy_F_angle = np.angle(test_noisy_F)\n",
    "\n",
    "    for batch_step in range(len(test_noisy_F_amp) / FLAGS.batch_size):\n",
    "        batch_noisy_eeg = test_noisy_F_amp[batch_step * FLAGS.batch_size : (batch_step + 1) * FLAGS.batch_size, :]\n",
    "        batch_noisy_eeg = np.reshape(batch_noisy_eeg, (-1, 1, BATCH_LENGTH, 1))\n",
    "\n",
    "        if(batch_noisy_eeg.shape == (FLAGS.batch_size, 1, BATCH_LENGTH, 1)):\n",
    "            batch_cleared, batch_noise = sess.run(signals, feed_dict={noisydata_ph: batch_noisy_eeg})\n",
    "            batch_cleared = batch_cleared.reshape(-1, BATCH_LENGTH)\n",
    "            cleared_F_amp = np.append(cleared_F_amp, batch_cleared, axis=0)\n",
    "            batch_noise = batch_noise.reshape(-1, BATCH_LENGTH)\n",
    "            noise_F_amp = np.append(noise_F_amp, batch_noise, axis=0)\n",
    "\n",
    "    Im_tmp = np.array([[1j for j in range(cleared_F_amp.shape[-1])] for i in range(len(cleared_F_amp))])\n",
    "    print ('cleared_F_amp.shape : {}'.format(cleared_F_amp.shape))\n",
    "    print ('test_noisy_F_angle.shape : {}'.format(test_noisy_F_angle.shape))\n",
    "    print ('Im_tmp.shape : {}'.format(Im_tmp.shape))\n",
    "    cleared_F = cleared_F_amp * np.cos(test_noisy_F_angle[:len(cleared_F_amp)]) + cleared_F_amp * np.sin(test_noisy_F_angle[:len(cleared_F_amp)]) * Im_tmp\n",
    "    cleared_eeg = np.fft.ifft(cleared_F)\n",
    "    cleared_eeg = cleared_eeg.ravel()\n",
    "    \n",
    "    noise_F = noise_F_amp * np.cos(test_noisy_F_angle[:len(noise_F_amp)]) + noise_F_amp * np.sin(test_noisy_F_angle[:len(noise_F_amp)]) * Im_tmp\n",
    "    noise_eeg = np.fft.ifft(noise_F)\n",
    "    noise_eeg = noise_eeg.ravel()\n",
    "\n",
    "    print('prediction noisydata finished !')\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare \"the spectrum of noisydata before added noise\" and \"cleared spectrum\"\n",
    "original_eeg = pd.read_csv('./data/clear/eeg_B6J5.csv', header=None, index_col=None).as_matrix()\n",
    "original_eeg = original_eeg.reshape(-1,BATCH_LENGTH)[2000:4000]\n",
    "\n",
    "original_F = np.fft.fft(original_eeg)\n",
    "original_F_amp = abs(original_F)\n",
    "original_F_angle = np.angle(original_F)\n",
    "\n",
    "print(original_F_amp[0:len(cleared_F_amp),0:len(cleared_F_amp[0])/2].shape)\n",
    "#print(len(cleared_F_amp))\n",
    "\n",
    "sihyou1 = np.mean(np.mean((original_F_amp[0:len(cleared_F_amp),0:len(cleared_F_amp[0])/2]/2500 - cleared_F_amp[:, 0:len(cleared_F_amp[0])/2]/2500) ** 2, axis=0), axis=0)\n",
    "sihyou2_low = np.mean(np.mean((cleared_F_amp[:, 0:11]/2500 - test_noisy_F_amp[0:len(cleared_F_amp), 0:11]/2500) ** 2, axis=0), axis=0)\n",
    "sihyou2_high = np.mean(np.mean((cleared_F_amp[:, 11:2500]/2500 - test_noisy_F_amp[0:len(cleared_F_amp), 11:2500]/2500) ** 2, axis=0), axis=0)\n",
    "\n",
    "print('siyou1 : {}'.format(sihyou1))\n",
    "print('siyou2_low : {}'.format(sihyou2_low))\n",
    "print('siyou2_high : {}'.format(sihyou2_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "y_lim = [0,500]\n",
    "\n",
    "ax1 = fig.add_subplot(621)\n",
    "ax1.plot(np.mean(test_noisy_F_amp/2500, axis=0)[0:30])\n",
    "plt.xticks([0,5,10,15,20,25,30], ['0','0.25','0.5','0.75','1.0','1.25','1.5'])\n",
    "plt.title('Input Spectrum Mean')\n",
    "plt.xlabel('Hz')\n",
    "plt.ylabel('micro V')\n",
    "ax1.set_ylim(y_lim)\n",
    "\n",
    "ax2 = fig.add_subplot(622)\n",
    "ax2.plot(np.mean(cleared_F_amp/2500, axis=0)[0:30])\n",
    "#ax2.plot(np.median(cleared_F_amp/2500, axis=0)[0:30], label='median')\n",
    "#ax2.plot(stats.scoreatpercentile(cleared_F_amp/2500, 25, axis=0)[0:30], label='25')\n",
    "#ax2.plot(stats.scoreatpercentile(cleared_F_amp/2500, 75, axis=0)[0:30], label='75')\n",
    "plt.xticks([0,5,10,15,20,25,30], ['0','0.25','0.5','0.75','1.0','1.25','1.5'])\n",
    "plt.title('Output Spectrum Mean')\n",
    "plt.xlabel('Hz')\n",
    "plt.ylabel('micro V')\n",
    "ax2.set_ylim(y_lim)\n",
    "\n",
    "ax5 = fig.add_subplot(623)\n",
    "ax5.plot(np.mean(clear_F_amp/2500, axis=0)[0:30])\n",
    "plt.xticks([0,5,10,15,20,25,30], ['0','0.25','0.5','0.75','1.0','1.25','1.5'])\n",
    "plt.title('Training Spectrum Mean')\n",
    "plt.xlabel('Hz')\n",
    "plt.ylabel('micro V')\n",
    "ax5.set_ylim(y_lim)\n",
    "\n",
    "ax6 = fig.add_subplot(624)\n",
    "ax6.plot(np.mean(test_noisy_F_amp/2500, axis=0)[0:30], label=\"input\")\n",
    "ax6.plot(np.mean(cleared_F_amp/2500, axis=0)[0:30], label=\"output\")\n",
    "ax6.plot(np.mean(clear_F_amp/2500, axis=0)[0:30], label=\"train\")\n",
    "plt.xticks([0,5,10,15,20,25,30], ['0','0.25','0.5','0.75','1.0','1.25','1.5'])\n",
    "plt.title('Overlaped Spectrum Mean')\n",
    "plt.xlabel('Hz')\n",
    "plt.ylabel('micro V')\n",
    "ax6.set_ylim(y_lim)\n",
    "plt.legend()\n",
    "\n",
    "ax3 = fig.add_subplot(625)\n",
    "ax3.plot(test_noisy_eeg.ravel()[0:250])\n",
    "plt.title('Input Signal Sample')\n",
    "plt.ylabel('micro V')\n",
    "\n",
    "ax4 = fig.add_subplot(626)\n",
    "ax4.plot(cleared_eeg[0:250])\n",
    "plt.title('Output Signal Sample')\n",
    "plt.ylabel('micro V')\n",
    "\n",
    "ax7 = fig.add_subplot(627)\n",
    "ax7.plot(test_noisy_eeg.ravel()[0:10000])\n",
    "plt.title('Input Signal Sample')\n",
    "plt.ylabel('micro V')\n",
    "\n",
    "ax8 = fig.add_subplot(628)\n",
    "ax8.plot(cleared_eeg[0:10000])\n",
    "plt.title('Output Signal Sample')\n",
    "plt.ylabel('micro V')\n",
    "\n",
    "ax9 = fig.add_subplot(629)\n",
    "ax9.plot(np.mean(noise_F_amp/2500, axis=0)[0:30])\n",
    "plt.xticks([0,5,10,15,20,25,30], ['0','0.25','0.5','0.75','1.0','1.25','1.5'])\n",
    "plt.title('Noise Spectrum Mean')\n",
    "plt.xlabel('Hz')\n",
    "plt.ylabel('micro V')\n",
    "ax9.set_ylim(y_lim)\n",
    "\n",
    "ax10 = fig.add_subplot(6,2,10)\n",
    "ax10.plot(noise_eeg[0:10000])\n",
    "plt.title('Noise Signal Sample')\n",
    "plt.ylabel('micro V')\n",
    "ax10.set_ylim(-8000,8000)\n",
    "\n",
    "ax11 = fig.add_subplot(6,2,11)\n",
    "ax11.plot(np.mean(test_noisy_F_amp[:, 200:300]/2500, axis=0), label=\"input\")\n",
    "ax11.plot(np.mean(cleared_F_amp[:, 200:300]/2500, axis=0), label=\"output\")\n",
    "ax11.plot(np.mean(clear_F_amp[:, 200:300]/2500, axis=0), label=\"train\")\n",
    "plt.title('Overlaped Spectrum Mean')\n",
    "plt.xlabel('Hz')\n",
    "plt.ylabel('micro V')\n",
    "ax11.set_ylim(20,80)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(len(cleared_F_amp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
